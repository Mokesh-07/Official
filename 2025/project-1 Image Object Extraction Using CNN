from google.colab import files
import numpy as np
import cv2
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import matplotlib.pyplot as plt

# Helper function to display images
def show_image(image, title="", cmap=None):
    plt.imshow(image, cmap=cmap)
    plt.axis("off")
    plt.title(title)

# Step 1: Upload the image
print("Please upload an image:")
uploaded = files.upload()

image_path = list(uploaded.keys())[0]
image = load_img(image_path)  # Load the uploaded image
image_array = img_to_array(image).astype(np.uint8)  # Convert image to array
original_image = np.copy(image_array)  # Keep a copy of the original
height, width, _ = image_array.shape

# Convert image to BGR for OpenCV
image_bgr = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)

# Step 2: Initialize the mask and region for GrabCut
mask = np.zeros((height, width), dtype=np.uint8)  # Initialize the mask

# Automatically set a rectangle covering most of the image
rect = (10, 10, width - 20, height - 20)  # Adjust to include the entire person

# Initialize background and foreground models for GrabCut
bgd_model = np.zeros((1, 65), np.float64)
fgd_model = np.zeros((1, 65), np.float64)

# Step 3: Apply GrabCut
cv2.grabCut(image_bgr, mask, rect, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_RECT)

# Generate the initial binary mask
initial_mask = np.where((mask == cv2.GC_FGD) | (mask == cv2.GC_PR_FGD), 1, 0).astype("uint8")

# Step 4: Refine the mask using morphology and iterative GrabCut
kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
refined_mask = cv2.morphologyEx(initial_mask, cv2.MORPH_CLOSE, kernel)

# Reapply GrabCut with the refined mask
mask[refined_mask == 1] = cv2.GC_FGD
mask[refined_mask == 0] = cv2.GC_BGD
cv2.grabCut(image_bgr, mask, None, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_MASK)

# Finalize the binary mask
final_mask = np.where((mask == cv2.GC_FGD) | (mask == cv2.GC_PR_FGD), 1, 0).astype("uint8")

# Create a transparent background which means background extraction
transparent_background = np.zeros((height, width, 4), dtype=np.uint8)
foreground = image_array * final_mask[:, :, np.newaxis]
transparent_background[:, :, :3] = foreground
transparent_background[:, :, 3] = (final_mask * 255).astype("uint8")  # Special channel

# Step 5: Display the results
plt.figure(figsize=(15, 10))

plt.subplot(1, 3, 1)
show_image(original_image / 255.0, title="Original Image")

plt.subplot(1, 3, 2)
show_image(final_mask, title="Refined Mask", cmap="gray")

plt.subplot(1, 3, 3)
show_image(transparent_background / 255.0, title="Object Detected Image")

plt.show()


